{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YsG-FBquCklc"
      },
      "source": [
        "# **Preinforme de trabajo #2(Parte Escrita)**\n",
        "24/03/2023\n",
        "\n",
        "## Integrantes:\n",
        "*   Esteban Roberto Saiz - esteban.roberto@udea.edu.co\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mDEPqNcxC84-"
      },
      "source": [
        "## **Punto 1**\n",
        "\n",
        "Consulte el qué es Numpy y qué es Pandas, defina en sus palabras qué aplicaciones pueden tener estas librerías para Bioingeniería.\n",
        "\n",
        "**Solución:**\n",
        "\n",
        "Numpy es una librería enfocada al cálculo numérico y permite trabajar con datos como si fueran \"matrices\" (llamados arrays o arreglos), y funciones para operaciones matemáticas rápidas en matrices, como operaciones de álgebra lineal\n",
        "\n",
        "Por otra parte, Pandas es una librería que permite trabajar con datos estructurados en filas y columnas (como una hoja de Excel) para la manipulación y el análisis de datos.\n",
        "\n",
        "Las aplicaciones de estas librerias para la Bioingeniería, principalmente se puede ver en el procesamiento de señales biomedicas como la electrocardiografía (ECG), la electromiografía (EMG) y la electroencefalografía (EEG), para analizar las señales y extraer características importantes para el diagnóstico y el tratamiento, y de igual forma, para la limpieza, manipulación y análisis de grandes conjuntos de datos biomédicos.\n",
        " \n",
        "__Referencias:__ \n",
        "\n",
        "[Pandas y Numpy](https://es.stackoverflow.com/questions/35908/python-modulos-numpy-y-pandas)\n",
        "\n",
        "[Pandas](https://datascientest.com/es/pandas-python#:~:text=La%20biblioteca%20de%20software%20de,manipular%20o%20incluso%20fusionar%20datos.)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T8TGYG9zDQ0_"
      },
      "source": [
        "## **Punto 2**\n",
        "\n",
        "Consulte cómo importar un set de datos desde Kaggle.com directamente a Collab y explique paso a paso cómo se hace.\n",
        "\n",
        "**Solución:**\n",
        "\n",
        "Para importar un set de datos desde Kaggle.com:\n",
        "\n",
        "1.) Abrimos Google Collab y creamos un nuevo cuaderno\n",
        "\n",
        "2.) Importamos la biblioteca kaggle ejecutando el codigo: __!pip install -q kaggle__\n",
        "\n",
        "3.) Descargamos el archivo de configuración de Kaggle API en la cuenta de Kaggle. Para esto, hay que ir a la cuenta de Kaggle, y hacer clic en \"Mi cuenta\" e ir hacia abajo hasta \"API\". Luego en \"Crear nueva clave API\" y descargar el archivo de configuración.\n",
        "\n",
        "4.) Luego en Colab, se sube el archivo de configuración al cuaderno Colab. Una manera de hacerlo es con: \n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()\n",
        "\n",
        "5.) Creamos una carpeta oculta en el sistema de archivos con el nombre .kaggle , movemos el archivo de configuración a la carpeta .kaggle en el directorio raíz. De la siguiente forma:\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "6.) Cambiamos los permisos para permitir lectura de las credenciales. Para hacer esto, escribimos lo siguiente:\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "7.) Buscamos el conjunto de datos que queremos importar en Kaggle.com y lo copiamos.\n",
        "\n",
        "8.) Pegamos el comando kaggle dataset download en Colab y ejecutamos el comando para descargar el conjunto de datos. Por ejemplo:\n",
        "\n",
        "!kaggle datasets download -d USERNAME/DATASETNAME\n",
        "\n",
        "Donde USERNAME/DATASETNAME son el nombre de usuario y el nombre del conjunto de datos que se desea descargar.\n",
        "\n",
        "10.) Descomprimimos el archivo descargado usando el siguiente código:\n",
        "\n",
        "!unzip DATASETNAME.zip\n",
        "\n",
        "Donde DATASETNAME lo reemplazamos con el nombre del archivo zip que acabamos de descargar.\n",
        "\n",
        "*_Referencias:_* \n",
        "\n",
        "[Usando la API de Kaggle con Google Colab](https://platzi.com/tutoriales/1794-pandas/6926-usando-la-api-de-kaggle-con-google-colab-para-carga-y-descarga-de-datasets/)\n",
        "\n",
        "[Cómo cargar Datasets de Kaggle en Google Colab](https://siriasadeddin.wixsite.com/siriaai/post/c%C3%B3mo-cargar-datasets-de-kaggle-en-google-colab)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Punto 3**\n",
        "\n",
        "Consulte cómo guardar y cargar datos en formato .npy (formato de guardado de Numpy), y realice un ejemplo práctico con ello.\n",
        "\n",
        "**Solución:**\n",
        "\n",
        "Para guardar y cargar datos en formato .npy de Numpy, realizamos lo siguiente:\n",
        "\n",
        "1.) Importamos la biblioteca numpy --> import numpy as np\n",
        "\n",
        "2.) Creamos un arreglo NumPy con los datos que queremos guardar. \n",
        "\n",
        "3.) Guardamos los datos en un archivo .npy usando la función __np.save__ --> np.save('data.npy', data)\n",
        "\n",
        "Donde se guardan los datos del arreglo data, en un archivo llamado data.npy\n",
        "\n",
        "4.) Para cargar los datos desde el archivo .npy, usamos la función np.load -->data_loaded = np.load('data.npy')\n",
        "\n",
        "Donde esto cargará los datos del archivo data.npy en el arreglo data_loaded\n",
        "\n",
        "\n",
        "*Referencias:* [Guardar y cargar NumPy Array en Python](https://www.delftstack.com/es/howto/numpy/python-save-and-load-numpy-array/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La lista original es: [1, 2, 3, 4, 5]\n",
            "El arreglo NumPy es: [1 2 3 4 5]\n",
            "El arreglo cargado desde el archivo .npy es: [1 2 3 4 5]\n"
          ]
        }
      ],
      "source": [
        "#Importamos la biblioteca numpy\n",
        "import numpy as np\n",
        "\n",
        "numeros = [1, 2, 3, 4, 5] #Creamos una lista de números\n",
        "\n",
        "numeros_array = np.array(numeros)#Convertimos la lista a un arreglo NumPy\n",
        "\n",
        "np.save('numeros.npy', numeros_array)#Guardar el arreglo en un archivo .npy\n",
        "\n",
        "\n",
        "numeros_cargados = np.load('numeros.npy')#Cargar el arreglo desde el archivo .npy\n",
        "\n",
        "# Imprimir\n",
        "print(\"La lista original es:\", numeros)\n",
        "print(\"El arreglo NumPy es:\", numeros_array)\n",
        "print(\"El arreglo cargado desde el archivo .npy es:\", numeros_cargados)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Punto 4**\n",
        "\n",
        "Consulte acerca del procesamiento de datos y defina en sus palabras cuáles son las partes más importantes de este.\n",
        "\n",
        "**Solución:**\n",
        "\n",
        "El procesamiento de datos es el conjunto de técnicas y herramientas utilizadas para convertir datos crudos en información útil y significativa. Lo cual permite limpiar, transformar y analizar los datos para obtener información que pueda ser utilizada para tomar decisiones o realizar predicciones.\n",
        "\n",
        "Las partes más importantes del procesamiento de datos son:\n",
        "\n",
        "1.) La limpieza de Datos.\n",
        "\n",
        "2.) Integracion de datos, donde combinamos datos de diferentes fuentes.\n",
        "\n",
        "3.) Transformacion de datos, donde se convierten los datos en una forma mas util para el analisis.\n",
        "\n",
        "4.) Analisis de datos.\n",
        "\n",
        "5.) Visualizar los datos.\n",
        "\n",
        "6.) Almacenamiento de datos.\n",
        "\n",
        "Por lo tanto, los pasos clave del procesamiento de datos contiene la limpieza, integración, transformación, análisis, visualización y almacenamiento de datos.\n",
        "\n",
        "Referencias: [Procesamiento Básico de Datos con Python](https://www.codigofuente.org/procesamiento-basico-de-datos-con-python/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "442367a78ad2513b796ad62e77bf8b114cdf9a8662c804798893dc403537c7f8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
